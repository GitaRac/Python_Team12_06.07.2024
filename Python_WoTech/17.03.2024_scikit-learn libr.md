# 17.03.2024 Python Teamwork 

    1. What is an error rate?
    2. Where you could use other machine-learning models?
    3. What is the difference between supervised and unsupervised training?
    4. How to import different models from the scikit-learn package?
    5. How can you evaluate the performance of a machine learning model in scikit-learn?
    6. What metrics are commonly used for evaluation?
    7. What is model overfitting, and how can it be prevented?

Linear regression modesls: https://scikit-learn.org/stable/modules/linear_model.html

The overall documentation: https://scikit-learn.org/stable

## 1. What is an error rate?

In machine learning, the error rate is a measure of how often a model makes mistakes when making predictions. It's the proportion of incorrect predictions out of all predictions made. For example, if a model predicts 100 sales and 20 of them are incorrect, the error rate is 20%. The goal is to minimize the error rate, which means the model is making more accurate predictions.

## 2. Where could you use other machine-learning models?

Scikit-learn provides a wide range of machine learning algorithms for various tasks, such as:

    **▪ Classification:** predicting a categorical label (e.g., spam vs. non-spam emails)
    ▪ Regression: predicting a continuous value (e.g., predicting house prices)
    ▪ Clustering: grouping similar data points together (e.g., customer segmentation)
    ▪ Dimensionality reduction: reducing the number of features in a dataset (e.g., image compression)

Some examples of other machine learning models include:

    ▪ Decision Trees: for classification and regression tasks
    ▪ Random Forests: an ensemble method that combines multiple decision trees
    ▪ Support Vector Machines (SVMs): for classification and regression tasks
    ▪ K-Means Clustering: for clustering tasks

## 3. What is the difference between supervised and unsupervised training?

Supervised learning: The model is trained on labeled data, where the correct output is already known. The goal is to learn a mapping between input data and output labels, so the model can make predictions on new, unseen data. Examples: classification, regression.

Unsupervised learning: The model is trained on unlabeled data, and the goal is to discover patterns, relationships, or groupings in the data. Examples: clustering, dimensionality reduction.

## 4. How to import different models from the scikit-learn package?

You can import scikit-learn models using the following syntax:

```py
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.cluster import KMeans
```

## 5. How can you evaluate the performance of a machine learning model in scikit-learn?

You can evaluate a model's performance using various metrics, such as:

    ▪ Accuracy: proportion of correct predictions
    ▪ Precision: proportion of true positives among all positive predictions
    ▪ Recall: proportion of true positives among all actual positive instances
    ▪ F1-score: harmonic mean of precision and recall
    ▪ Mean Squared Error (MSE): average squared difference between predicted and actual values

Scikit-learn provides functions to calculate these metrics, such as accuracy_score, precision_score, recall_score, f1_score, and mean_squared_error.

## 6. What metrics are commonly used for evaluation?

The choice of metric depends on the problem type:

    ▪ Classification: accuracy, precision, recall, F1-score
    ▪ Regression: mean squared error (MSE), mean absolute error (MAE), R-squared
    ▪ Clustering: silhouette score, calinski-harabasz index

## 7. What is model overfitting, and how can it be prevented?

Overfitting: when a model is too complex and learns the noise in the training data, resulting in poor performance on new, unseen data.

To prevent overfitting:
    ▪ Regularization: add a penalty term to the loss function to discourage large weights
    ▪ Early stopping: stop training when the model's performance on the validation set starts to degrade
    ▪ Data augmentation: increase the size of the training set by applying transformations to the existing data
    ▪ Ensemble methods: combine multiple models to reduce overfitting
    ▪ Cross-validation: evaluate the model on multiple subsets of the data to estimate its performance on unseen data
